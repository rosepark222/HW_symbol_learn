# Bidirectional Recurrent Neural Network Training 

Summary: Imagine a kid works on math problems using math equations in her iPad software and she (or he) writes down her answer using Apple Pencil. When iPad software recognizes her answer is wrong, it will provide relevant mini problems to help her to learn necessary concepts to solve the original math problem. Meanwhile, her misconceptions are analyzed from her math equation answer and appropriate feedback will be generated for her teachers or parents. This project is a baby step for this lofty goal. An essential technique of this learning platform is called Handwritten Recognition System for Math Equations. As of today, a bidirectional RNN has been trained to recognize 53 math strokes (not symbols -- details come below). Additional processing is planned to bring this recognition to symbol and equation level for complete math equation recognition.

I think the best way to have the feel for this project is to dabble with the deployment in Google cloud:http://pradoxum001.appspot.com/

For some background information about data preparation, please read https://github.com/rosepark222/HW_Rcode

A bidirectional RNN was trained to recognize strokes. The dimensions of input, the first and second hidden layers are 15, 64 and 32, respectively. [LSTM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) cells were used to overcome vanishing gradient issue and when it is necessary to forget previously learnined information. For example, when the subjects in sentences have changed from singular and plural in Natural Language Processing, the previously registered information of the subject being singular should be forgotten and updated by the current information. 

Prior to the training, data were balanced to have 1000 sample per strokes (data are copied when the numbers of a stroke is less than 1000). Total 53 strokes are trained. At the end of training, the loss, mse and accuracy were close to 0.002, 3E-6, and .999. Splitting of training and test sets were useful at the beginning of the project. After the model was deployed to Google cloud, more online experiments were utilized to evaluate the performance. The interface to the deployment can be leveraged to collect handwritten strokes data. This may be a good future development, because currently data are lacking in some strokes. 

The batch size was 500, the number of steps in epoch is 30 and the number of epochs for the optimization was slightly above 1,000. The learning rate was not adjusted at this moment. For this reason, there are some spikes of loss values after they became smaller than 0.01. I believe adjusting the learning rate would prevent the jittery behavior of optimization toward the end of optimization. I programmed Keras to save model parameters whenever the loss decreases from the previous epoch during the training. In this way, the simulation always store the best result during the training.

In the current project, I am still not clear how the forget gates in LSTM would help the learning. It is still observed that the network did not learn the differences between similar symbols such as 9 and g, q. To make things worse, if one stroke completely overlaps with another (such as ‘s’ and ‘8’, when both are drawn in counterclockwise from top to bottom), RNN often failed to classify them. Empirical tests showed that 8 was confused with s but s was not confused with 8. An interesting note is that 8 written in clockwise was not confused with s written in counterclockwise. At the beginning of the project, there was an issue that RNN was confused the left stroke of lower case x (flipped c) and number 2. When I added offline features (see Marti and Bunke [2001]), this confusion *magically* disappeared. I believe this is because offline features were distinct between the two strokes. 

The good news is that this is not the end of the road. Additional models such as Convolutional Neural Network (CNN) can be added to distinguish strokes, which are challenging for RNN to classify. The sample size of unique s and 8 are 170 and 760, respectively, and they were duplicated (copied) to be 1000 to be balanced with other symbols. In my opinion, these sample sizes seems too small for any neural network to learn. I believe that RNN should be able to learn when more data would be added.  

Important factors that have improved the learning are -- adopting bidirectional RNN, adding offline features, balancing the data, removing mislabeled strokes. These design choices are ordered in the sequence of implementation, not in its amount of impact on the performance. The learning is not perfect - meaning there are misclassifications. As long as the confusions are consistent, however, the correct recognition can be accomplished using probablistic language model. Further, the problems in an e-learning platform may provide extra information regarding the likelihood of the symbol. For example, students are likely to use k in their answers if the description of the problem uses k as a variable. The problem can even force students to use certain symbols to describe their answers. Based on this contextual information, developing probabilistic models for recognizing symbols from strokes is the next step in the project.  

     
